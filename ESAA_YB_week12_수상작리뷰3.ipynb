{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0H4aFOk4aUu0IdglPYuW9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanbiphyun/ESSA_YB/blob/main/ESAA_YB_week12_%EC%88%98%EC%83%81%EC%9E%91%EB%A6%AC%EB%B7%B03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "링크 : https://dacon.io/competitions/official/236439/codeshare/12230\n",
        "\n",
        "##부동산 허위매물 분류 프로젝트\n",
        "\n",
        "###1. 프로젝트 개요\n",
        "\n",
        "본 작업은 부동산 플랫폼에 등록된 매물 정보를 기반으로 **해당 매물이 허위매물인지 여부(0: 실매물, 1: 허위매물)** 를 예측하는 이진 분류 문제를 해결하는 과정 전반을 분석한 내용이다. 사용된 데이터는 총 2452개 행, 17개 컬럼으로 구성되어 있으며, 매물의 보증금·월세·전용면적·층수·방향 등 다양한 정형 데이터로 이루어져 있다.\n",
        "\n",
        "###2. 데이터 구성\n",
        "\n",
        "데이터는 아래와 같은 주요 변수로 구성되어 있다.\n",
        "\n",
        "ID\n",
        "\n",
        "매물확인방식\n",
        "\n",
        "보증금\n",
        "\n",
        "월세\n",
        "\n",
        "전용면적\n",
        "\n",
        "해당층\n",
        "\n",
        "총층\n",
        "\n",
        "방향\n",
        "\n",
        "방수\n",
        "\n",
        "욕실수\n",
        "\n",
        "주차가능여부\n",
        "\n",
        "총주차대수\n",
        "\n",
        "관리비\n",
        "\n",
        "중개사무소\n",
        "\n",
        "제공플랫폼\n",
        "\n",
        "게재일\n",
        "\n",
        "허위매물여부 (타겟)\n",
        "\n",
        "\n",
        "###**3. 데이터 전처리**\n",
        "\n",
        "3.1 결측치 처리\n",
        "\n",
        "- 수치형 변수는 평균값으로 대체하였다.\n",
        "\n",
        "- 범주형 변수는 추후 레이블 인코딩을 위해 원본 그대로 유지하였다.\n",
        "\n",
        "3.2 이상치 제거 (DBSCAN)\n",
        "\n",
        "- DBSCAN은 밀도 기반 클러스터링 알고리즘으로, 주변에 충분한 데이터가 존재하지 않는 점들을 노이즈(-1)로 분류한다.\n",
        "\n",
        "- 사용한 주요 설정:\n",
        "\n",
        "표준화(StandardScaler) 적용\n",
        "\n",
        "eps = 2.5\n",
        "\n",
        "min_samples = 5\n",
        "\n",
        "- DBSCAN을 적용한 결과, 노이즈로 판단된 7개 행을 제거하여 2452 → 2445개 데이터로 정제하였다.\n",
        "\n",
        "이유:\n",
        "\n",
        "부동산 데이터는 보증금, 월세 등 값의 범위가 매우 넓어 극단치(outlier)가 많다.\n",
        "\n",
        "거리 기반 이상치 탐지는 스케일링을 통해 단위를 맞춰야 효과적으로 작동한다.\n",
        "\n",
        "DBSCAN은 비선형·비정규 데이터에 강하며 복잡한 이상치 패턴을 탐지하는 데 적합하다.\n",
        "\n",
        "###**4. 범주형 변수 처리 (Label Encoding)**\n",
        "4.1 훈련 데이터 인코딩\n",
        "\n",
        "- 범주형 변수: 중개사무소, 제공플랫폼, 방향, 매물확인방식, 주차가능여부\n",
        "\n",
        "- 컬럼별로 LabelEncoder 객체를 따로 생성하여 각 범주의 정수 매핑을 학습한다.\n",
        "\n",
        "- 모든 인코더를 딕셔너리에 저장한다.\n",
        "\n",
        "4.2 테스트 데이터 인코딩\n",
        "\n",
        "- train에서 학습된 인코더를 그대로 사용해야 데이터 누수가 발생하지 않는다.\n",
        "\n",
        "- test 데이터에 훈련 데이터에 없던 새로운 범주가 존재할 경우,\n",
        "classes_ 에 해당 범주를 추가한 후 transform을 진행한다.\n",
        "\n",
        "- 이는 실제 서비스 환경에서 매우 중요한 처리 방식이다.\n",
        "\n",
        "###**5. 다중공선성 확인**\n",
        "\n",
        "- Heatmap과 Variance Inflation Factor(VIF)를 활용해 변수 간 상관성을 검사하였다.\n",
        "\n",
        "- 상관계수는 최대 약 0.3 수준으로 낮았으며,\n",
        "VIF 역시 10을 넘는 변수는 없었으므로 변수를 제거하지 않았다.\n",
        "\n",
        "###**6. 모델 학습**\n",
        "6.1 XGBoost Classifier 사용\n",
        "\n",
        "- 기본 모델:\n",
        "XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "6.2 RandomizedSearchCV를 통한 하이퍼파라미터 탐색\n",
        "- 탐색한 주요 파라미터 범위:\n",
        "\n",
        "n_estimators\n",
        "\n",
        "learning_rate\n",
        "\n",
        "max_depth\n",
        "\n",
        "min_child_weight\n",
        "\n",
        "subsample\n",
        "\n",
        "colsample_bytree\n",
        "\n",
        "gamma\n",
        "\n",
        "reg_alpha\n",
        "\n",
        "reg_lambda\n",
        "\n",
        "scale_pos_weight\n",
        "\n",
        "max_delta_step\n",
        "\n",
        "설정:\n",
        "\n",
        "n_iter = 50\n",
        "\n",
        "cv = 5\n",
        "\n",
        "평가 지표: f1_macro\n",
        "\n",
        "n_jobs = -1\n",
        "\n",
        "- RandomizedSearchCV는 GridSearch보다 훨씬 적은 연산으로 넓은 탐색 공간을 빠르게 점검할 수 있다는 장점이 있다.\n",
        "\n",
        "###**7. 인사이트**\n",
        "7.1 얻은 인사이트\n",
        "\n",
        "1. DBSCAN 기반 이상치 제거 전략\n",
        "부동산 데이터는 연속형 변수의 범위가 넓고 극단치가 많아 단순 IQR 방식보다 DBSCAN이 효과적이었다.\n",
        "\n",
        "2. 범주형 인코딩에서의 데이터 누수 방지 처리\n",
        "LabelEncoder 사용 시 train과 test 간 매핑 불일치 문제를 적절히 해결했다.\n",
        "\n",
        "3. RandomizedSearchCV의 효율성\n",
        "모든 조합을 탐색하는 GridSearch보다 훨씬 빠르고 실용적이다.\n",
        "\n",
        "7.2 수상작의 보완점\n",
        "\n",
        "1. Feature Engineering이 거의 수행되지 않았으며, 도메인 기반 피처 추가 여지가 많다.\n",
        "\n",
        "2. XGBoost 단일 모델만 사용했는데,\n",
        "LightGBM, CatBoost, Stacking 등을 사용하면 성능 향상을 기대할 수 있다."
      ],
      "metadata": {
        "id": "lksIFflxDOPR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLrIpGiUB0Xs"
      },
      "outputs": [],
      "source": []
    }
  ]
}